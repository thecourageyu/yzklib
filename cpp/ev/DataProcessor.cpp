#include "DataProcessor.h"   // ğŸ‘ˆ make sure this is at the top

#include <iostream>
#include <regex>
#include <sstream>

#include "include/nlohmann/json.hpp"
using json = nlohmann::json;   // alias (optional)
// sudo apt-get install nlohmann-json3-dev
// wget https://github.com/nlohmann/json/releases/download/v3.11.3/json.hpp -O json.hpp

// helper: convert Python-style dict string into JSON-like string
std::string DataProcessor::pythonDictToJson(std::string s) {
    // replace single quotes with double quotes
    for (auto& c : s) {
        if (c == '\'') c = '"';
    }

    // replace Python booleans with JSON booleans
    s = std::regex_replace(s, std::regex("\\bTrue\\b"), "true");
    s = std::regex_replace(s, std::regex("\\bFalse\\b"), "false");

    // replace Python None with JSON null (if ever appears)
    s = std::regex_replace(s, std::regex("\\bNone\\b"), "null");
    // std::cout << s << std::endl;
    return s;
}

std::vector<ToolCall> DataProcessor::parseToolCalls(const std::string &inputText) {
    std::string text = inputText;
    std::vector<ToolCall> tool_calls;

    // Remove <hhev_end>
    size_t pos;
    std::string cleaned = text;
    while ((pos = cleaned.find("<hhev_end>")) != std::string::npos) {  // no position
        cleaned.erase(pos, std::string("<hhev_end>").length());
    }

    // Split on <hhev_split>
    std::vector<std::string> tools;
    size_t start = 0, end;
    while ((end = cleaned.find("<hhev_split>", start)) != std::string::npos) {
        tools.push_back(cleaned.substr(start, end - start));
        start = end + std::string("<hhev_split>").length();
    }
    tools.push_back(cleaned.substr(start));

    // Regex to match <tool>(args)
    std::regex re("<(.*)>\\((.*)\\)");

    for (const auto& tool : tools) {
        std::smatch match;
        if (std::regex_search(tool, match, re)) {
            std::string tool_name = match[1];
            std::string tool_args = match[2];
            
            try {
                std::string fixed_args = DataProcessor::pythonDictToJson(tool_args);
                json parsed = json::parse(fixed_args);
                tool_calls.push_back({tool_name, parsed});
            } catch (std::exception& e) {
                std::string fixed_args = DataProcessor::pythonDictToJson(tool_args);
                // Fallback: store raw string if JSON parse fails
                tool_calls.push_back({tool_name, fixed_args});
                std::cerr << "[ERR] parse tool args failed! " 
                          << tool_name << ", " << fixed_args << "\n" 
                          << e.what() << std::endl;
            }
        }
    }

    return tool_calls;
}


std::string DataProcessor::build_chat_template(
        const std::vector<std::pair<std::string, std::string>> &history) {
    std::ostringstream oss;
    for (auto &msg : history) {
        oss << "<|start_header_id|>" << msg.first << "<|end_header_id|>\n\n"
            << msg.second << "<|eot_id|>";
    }
    oss << "<|start_header_id|>assistant<|end_header_id|>\n\n";
    return oss.str();
}


std::string DataProcessor::buildPlannerChatTemplate(const std::vector<std::pair<std::string, std::string>> &history) {

    std::unordered_map<std::string, std::string> roleMapping;
    roleMapping["user"] = "user";
    roleMapping["assistant"] = "assistant";
    roleMapping["ipython"] = "ipython";
    roleMapping["observation"] = "ipython";
    roleMapping["tool"] = "ipython";

    std::ostringstream oss;
    for (auto &msg : history) {

        oss << "<|start_header_id|>" << roleMapping[msg.first] << "<|end_header_id|>\n\n"
            << msg.second << "<|eot_id|>";
    }
    oss << "<|start_header_id|>assistant<|end_header_id|>\n\n";
    return oss.str();
}


std::string DataProcessor::buildSolverChatTemplate(const std::vector<std::pair<std::string, std::string>> &history) {
    std::string SOLVER_SYSTEM_PROMPT = R"(You are an AI assistant tasked with improving a response using full context from a multi-turn interaction.

You are given:
- The user query
- The function call and its result
- The original assistant response

Your goal is to revise or regenerate the assistant response to be more helpful, accurate, and fluent.
Use the function result meaningfully. Improve clarity, tone, or completeness if needed. If the original response is already good, polish it slightly.

Respond only with the improved message (do not explain or output metadata).
)";

    std::string SOLVER_PROMPT = R"(
---

{}

---

Improved Response:
)";

// <|eot_id|><|start_header_id|>user<|end_header_id|>


// ---

// user: æˆ‘æƒ³è¦å»ç§‘å­¸å¯¦é©—å®¤é¢¨çš„å¤œå¸‚çœ‹çœ‹
// function_call: <search_and_show_place>({'keyword': 'ç§‘å­¸å¯¦é©—å®¤é¢¨çš„å¤œå¸‚'})<hhev_end>
// observation: {"name": "search_and_show_place", "status": "success", "message": "åœ°é»æŸ¥è©¢æˆåŠŸ", "poi": [{"name": "æ–°ç«¹åŸéšå¤œå¸‚", "address": "æ–°ç«¹å¸‚åŒ—å€ä¸­å±±è·¯88è™Ÿ", "latitude": 24.8071, "longitude": 120.9688, "fromMemory": true}, {"name": "å£«æ—è§€å…‰å¤œå¸‚", "address": "å°åŒ—å¸‚å£«æ—å€å¤§æ±è·¯100è™Ÿ", "latitude": 25.087611, "longitude": 121.525621, "fromMemory": false}]}
// assistant: ä¸Šæ¬¡æ‚¨æ˜¯å»æ–°ç«¹åŸéšå¤œå¸‚ï¼Œé€™æ¬¡é‚„è¦å»é€™è£¡å—ï¼Ÿ
// user: æ‡‰è©²ä¸æ˜¯é€™ä¸€é–“
// assistant: è«‹å‘Šè¨´æˆ‘ç›®çš„åœ°é™„è¿‘çš„æ¨™èªŒæ€§æ™¯é»æˆ–æè¿°ç§‘å­¸å¯¦é©—å®¤é¢¨çš„å¤œå¸‚çš„å…·é«”ç‰¹å¾µï¼Œé€™æ¨£æˆ‘å¯ä»¥æ›´ç²¾æº–åœ°å¹«ä½ æœå°‹ä¸¦å°èˆªåˆ°æ­£ç¢ºçš„åœ°å€
// user: åº—åæœ‰é€¢ç”²
// function_call: <search_and_show_place>({'keyword': 'ç§‘å­¸å¯¦é©—å®¤é¢¨çš„å¤œå¸‚ é€¢ç”²'})<hhev_end>
// observation: {"name": "search_and_show_place", "status": "success", "message": "åœ°é»æŸ¥è©¢æˆåŠŸ", "poi": [{"name": "é€¢ç”²å¤œå¸‚", "address": "å°ä¸­å¸‚è¥¿å±¯å€æ–‡è¯è·¯100è™Ÿ", "latitude": 24.178943, "longitude": 120.6461, "fromMemory": false}]}
// assistant: æˆ‘æ‰¾åˆ°é€¢ç”²å¤œå¸‚ï¼Œè«‹å•æ˜¯è¦åˆ°é€™è£¡å—ï¼Ÿ


// ---

// Improved Response:

   
// std::string build_solver_prompt(const std::vector<json>& messages) {
    std::string chat_hist;
    std::string prev_role;
    std::string prev_content;

    for (const auto &msg : history) {
        // std::string role = msg.at("role");
        // std::string content = msg.at("content");
        std::string role = msg.first;
        std::string content = msg.second;

        if (role == "user") {
            chat_hist += "user: " + content + "\n";
        } 
        else if (role == "assistant") {
            if (prev_role == "ipython") {
                chat_hist += "assistant: " + content + "\n";
            } else {
                if (content.find("<hhev_end>") != std::string::npos) {
                    chat_hist += "function_call: " + content + "\n";
                } else {
                    chat_hist += "assistant: " + content + "\n";
                }
            }
        } 
        else if (role == "ipython") {
            chat_hist += "observation: " + content + "\n";
        }

        prev_role = role;
        prev_content = content;
    }

    // Equivalent to Python f-string formatting
    std::string prompt;
    prompt += "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\n" + SOLVER_SYSTEM_PROMPT + "\n<|eot_id|>";
    
    // Replace "{}" in SOLVER_PROMPT with chat_hist
    std::string user_block = SOLVER_PROMPT;
    size_t pos = user_block.find("{}");
    if (pos != std::string::npos) {
        user_block.replace(pos, 2, chat_hist);
    }

    prompt += "<|start_header_id|>user<|end_header_id|>\n\n" + user_block + "<|eot_id|>";
    prompt += "<|start_header_id|>assistant<|end_header_id|>\n\n";

    return prompt;
}


